{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled17.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMWLomAaAN1gfF/4x8iWhSV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samarcherif/Chatbot-/blob/master/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0LIWHyduQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary libraries\n",
        "import random\n",
        "import string # to process standard python strings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awY9ZxWo4KeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1e7cb05a-c312-46d7-c5f2-a36945d031d0"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc7gCsB0eaFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading in the data\n",
        "with open('/content/sample_data/Data.txt','r',errors ='ignore') as fin:\n",
        "    raw = fin.read().lower()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ys5IhamxB6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize our data \n",
        "sent_tokens = nltk.sent_tokenize(raw)# we convert our data to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw)# here we convert our data  to list of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQQtuuySxtfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The idea here we do the preprocessing data that we introduced in the first part of the project \n",
        "\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvsd1eNDylvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I create a function greeting that i put some random inputs and response for greeting \n",
        "GREETING_INPUTS = (\"hello\", \"hi\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zgEd7Xpypwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "610939e4-8e3b-4674-9fe2-dc276ea74b17"
      },
      "source": [
        "greeting('hi')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq5C9mUIGK5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The idea here i use the tf idf to create a vector and then i use similarity cosinus to show the similar vector \n",
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    Tfidf = TfidfVectorizer(tokenizer=LemNormalize)\n",
        "    all_word_vectors = Tfidf.fit_transform(sent_tokens)\n",
        "    similar_vector = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
        "    idx=similar_vector.argsort()[0][-2]\n",
        "    matched_our_vector = similar_vector.flatten()\n",
        "    matched_our_vector.sort()\n",
        "    req_tfidf = matched_our_vector[-2]\n",
        "    \n",
        "    \n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! can you explain me more\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwtLsHj9GM_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "ddf61e45-5d0e-4d92-be8c-bf5ab4120e19"
      },
      "source": [
        "\n",
        "dialogue=True\n",
        "print(\"ROBO: My name is Robo. I will answer all your question!\")\n",
        "print(\"ROBO: if you want to quit the discussion you just print bye\")\n",
        "\n",
        " #The idea here if the robo say bye so we quite the dialogue \n",
        " #If the robo say greeting so we choose something from the function that we created \"def greeting\"\n",
        " #If the user say something related to the subject so for answer we use reponse funtion \n",
        "while(dialogue==True):\n",
        "    user_response = input(\"user:\")\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            dialogue=False\n",
        "            print(\"ROBO: You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO: \",greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        dialogue=False\n",
        "        print(\"ROBO: Bye! \")\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROBO: My name is Robo. I will answer all your question!\n",
            "ROBO: if you want to quit the discussion you just print bye\n",
            "user:Hi\n",
            "ROBO:  hi\n",
            "user:How we can get a strong heart?\n",
            "ROBO: how to get a strong heart\n",
            "to get a strong heart you need to have 7 powerful ways \n",
            "get moving \n",
            "quit smoking \n",
            "lose weight \n",
            "eat heart-healthy foods\n",
            "don't forget the chocolate\n",
            "don't overeat\n",
            "don't stress.\n",
            "user:what do you think about the product Follicle RX ?\n",
            "ROBO: follicle rx\n",
            "follicle rx is the worst product that i had use.it is not prevention for hair fall or growth medicine, by using that it one can gradually face more hair fall.while company suggest when using in the earlier stage one can face many hair fall, but it does not recover at all.so please don't come into fake product with fake label.\n",
            "user:How can you describe kinetic energy?\n",
            "ROBO: the kinetic energy\n",
            "in physics, the kinetic energy (ke) of an object is the energy that it possesses due to its motion.\n",
            "user:What damages the ozone layer?\n",
            "ROBO: ozone\n",
            "ozone depletion does not cause global warming, but both of these environmental problems have a common cause: human activities that release pollutants into the atmosphere altering it.\n",
            "user:What do you mean by a potential?\n",
            "ROBO: potential\n",
            "potential is existing in possibility : capable of development into actuality.\n",
            "user:Who is Richard T. Liddicoat, Jr.?\n",
            "ROBO: richard t\n",
            "richard t. liddicoat, jr. (march 2, 1918 july 23, 2002) was an american gemologist.\n",
            "user:Where is Nirav Modi hiding?\n",
            "ROBO: finally, political pressure will catch up with whichever country he is hiding in sooner or later.\n",
            "user:thanks\n",
            "ROBO: You are welcome..\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}